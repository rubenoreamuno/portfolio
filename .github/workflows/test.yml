name: Portfolio Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  syntax-tests:
    name: Syntax Validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install kafka-python pandas numpy scikit-learn
      
      - name: Run syntax tests
        run: |
          echo "## Syntax Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          total=0
          passed=0
          failed=0
          
          for dir in 0* 1*; do
            if [ -d "$dir" ]; then
              echo "Testing: $dir"
              py_files=$(find "$dir" -name '*.py' -type f ! -name '._*' 2>/dev/null | wc -l)
              if [ $py_files -gt 0 ]; then
                errors=0
                for file in $(find "$dir" -name '*.py' -type f ! -name '._*' 2>/dev/null); do
                  if ! python -m py_compile "$file" 2>/dev/null; then
                    echo "âŒ Error in: $file" >> $GITHUB_STEP_SUMMARY
                    ((errors++))
                  fi
                done
                if [ $errors -eq 0 ]; then
                  echo "âœ… $dir: All Python files valid ($py_files files)" >> $GITHUB_STEP_SUMMARY
                  ((passed++))
                else
                  echo "âŒ $dir: Found $errors error(s)" >> $GITHUB_STEP_SUMMARY
                  ((failed++))
                fi
                ((total++))
              fi
            fi
          done
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Summary:** âœ… Passed: $passed | âŒ Failed: $failed | Total: $total" >> $GITHUB_STEP_SUMMARY
          
          if [ $failed -gt 0 ]; then
            exit 1
          fi

  functional-tests:
    name: Functional Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install kafka-python pandas numpy scikit-learn
      
      - name: Run functional tests
        run: |
          echo "## Functional Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test 1: Kafka Producer
          echo "### Test 1: Kafka Producer Event Generation" >> $GITHUB_STEP_SUMMARY
          cd 01-realtime-streaming-pipeline
          python3 << 'ENDPYTHON' && echo "âœ… PASSED" >> $GITHUB_STEP_SUMMARY || echo "âŒ FAILED" >> $GITHUB_STEP_SUMMARY
import sys
sys.path.insert(0, 'kafka')
from producer import EventProducer

producer = EventProducer()
event = producer.generate_event()

assert 'event_id' in event
assert 'timestamp' in event
assert 'event_type' in event
assert 'user_id' in event
assert 'properties' in event

print(f"âœ“ Event generated: {event['event_type']}")
ENDPYTHON
          cd ..
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test 2: Data Quality
          echo "### Test 2: Data Quality Framework" >> $GITHUB_STEP_SUMMARY
          cd 02-data-quality-framework
          python3 << 'ENDPYTHON' && echo "âœ… PASSED" >> $GITHUB_STEP_SUMMARY || echo "âŒ FAILED" >> $GITHUB_STEP_SUMMARY
import sys
sys.path.insert(0, 'src')
import pandas as pd
from validators.completeness_validator import CompletenessValidator

df = pd.DataFrame({
    'id': [1, 2, None],
    'email': ['a@test.com', 'b@test.com', 'c@test.com']
})

validator = CompletenessValidator('test', ['id'], 0.1)
result = validator.validate(df)

if not result.passed and len(result.details.get('issues', [])) > 0:
    print("âœ“ Validator working correctly")
else:
    exit(1)
ENDPYTHON
          cd ..
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test 3: Anomaly Detection
          echo "### Test 3: Anomaly Detection" >> $GITHUB_STEP_SUMMARY
          cd 07-anomaly-detection
          python3 << 'ENDPYTHON' && echo "âœ… PASSED" >> $GITHUB_STEP_SUMMARY || echo "âŒ FAILED" >> $GITHUB_STEP_SUMMARY
import sys
sys.path.insert(0, 'src')
import pandas as pd
import numpy as np
from detectors.isolation_forest import IsolationForestDetector

np.random.seed(42)
X = pd.DataFrame(
    np.vstack([np.random.randn(100, 3), np.random.randn(10, 3) + 5]),
    columns=['f1', 'f2', 'f3']
)

detector = IsolationForestDetector(0.1)
detector.fit(X)
results = detector.detect_anomalies(X, 0.3)
anomalies = results[results['is_anomaly']]

if len(anomalies) > 0:
    print(f"âœ“ Anomalies detected: {len(anomalies)}")
else:
    exit(1)
ENDPYTHON
          cd ..
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test 4: Pipeline
          echo "### Test 4: Pipeline Orchestration" >> $GITHUB_STEP_SUMMARY
          cd 09-pipeline-orchestration
          python3 << 'ENDPYTHON' && echo "âœ… PASSED" >> $GITHUB_STEP_SUMMARY || echo "âŒ FAILED" >> $GITHUB_STEP_SUMMARY
import sys
sys.path.insert(0, 'src')
from pipelines.etl_pipeline import ETLPipeline

pipeline = ETLPipeline('test')
pipeline.add_task('extract', lambda: {'data': 'extracted'})
pipeline.add_task('load', lambda: {'data': 'loaded'}, ['extract'])
result = pipeline.execute()

if result['status'] == 'success':
    print("âœ“ Pipeline working")
else:
    exit(1)
ENDPYTHON
          cd ..
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**All functional tests completed!**" >> $GITHUB_STEP_SUMMARY

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [syntax-tests, functional-tests]
    if: always()
    steps:
      - name: Check test results
        run: |
          echo "## ðŸŽ‰ All Tests Completed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the previous jobs for detailed results." >> $GITHUB_STEP_SUMMARY

